---
title: "Assignment 5"
author: "Erik Nylander"
date: "Saturday, February 21, 2015"
output: html_document
---

### Problem Set 1
For the first problem I will be looking at the system $A x = b$ as given:
$$
\begin{bmatrix} 1 & 0 \\ 1 & 1 \\ 1 & 3 \\ 1 & 4 \end{bmatrix}
\begin{bmatrix} x_1 \\ x_2 \end{bmatrix} = 
\begin{bmatrix} 0 \\ 8 \\ 8 \\ 19 \end{bmatrix}
$$
First lets compute $A^T A$ and $A^T b$ and store those values:
```{r}
A <- matrix(c(1,1,1,1,0,1,3,4), nrow=4)
b <- matrix(c(0,8,8,20), nrow=4)
# Now to compute A^TA and A^Tb
ATA <- t(A)%*%A
ATb <- t(A)%*%b
```
This yields the following two matrices:
```{r}
ATA
ATb
```
Now that I have these two matrices I can compute the a solution to $\hat{x}$. To do this I'll use R to calculate the following $(A^T A)^{-1} (A^T b)$:
```{r}
xhat <- solve(ATA) %*% ATb
xhat
```
This gives a least squares approximation of $\begin{bmatrix} x_1 \\ x_2 \end{bmatrix} = \begin{bmatrix} 1 \\ 4\end{bmatrix}$


Now I'll use the bestfitting solution vector $\hat{x}$ to calculate $p$. This vector represents the answer that we get from multiplying $A \hat{x}$. I'll use the vector to find the residuals and compute the square error:
```{r}
# The approximation for b resulting from least squares solution method.
p <- A%*%xhat
p
# Computing the error vector e = p-b.
e <- p - b
e
# Finding the square error.
square.error <- sum((e)^2)
square.error
```
This gives a square error of 44 for the solution $\begin{bmatrix} x_1 \\ x_2 \end{bmatrix} = \begin{bmatrix} 1 \\ 4 \end{bmatrix}$.

Finally lets show that this vector of residual errors $e$ is orthogonal to $p$ and to the columns of $A$ by showing that the dot product is 0. I'll use round to handle slight computational errors.
```{r}
# e and p orthogonal
round(sum(e*p), digits = 6)
# e and the columns of A
round(sum(e*A[,1]), digits = 6)
round(sum(e*A[,2]), digits = 6)
```
This shows that the vector of residuals is orthogonal to the projection $p$ and the column space of $A$


Next I'll use a $p = \begin{bmatrix} 1 \\ 5 \\ 13 \\ 17 \end{bmatrix}$ and calcuate the same results as above for a system that can be solved.
```{r}
p = matrix(c(1,5,13,17), nrow=4)
ATp <- t(A) %*% p
ATp
```

Now I can solve for $\hat{x}$ by finding $(A^T A)^{-1} (A^T b_2)$
```{r}
xhat.p <- solve(ATA) %*% ATp 
xhat.p
```
This gives a least squares approximation of $\begin{bmatrix} x_1 \\ x_2 \end{bmatrix} = \begin{bmatrix} 1 \\ 4 \end{bmatrix}$

Next I'll compute the error vector and the square error for $p$
```{r}
p2 <- A%*%xhat.p
e2 <- round(p2 - p, digits = 6)
e2
psquare.error <- round(sum((p2-p)^2), digits=6)
psquare.error
```
The result of using $b_2$, which yields a solvable system of equations and gives the a square error of 0 and an $e = \begin{bmatrix} 0 \\ 0 \\ 0 \\ 0 \end{bmatrix}$. This shows that we have a solvable system of equations.

Finally lets show that this vector of residual errors $e_2$ is orthogonal to $p$ and to the columns of $A$ by showing that the dot product is 0. I'll use round to handle slight computational errors.
```{r}
# e and p orthogona
sum(e2*p2)
# e and the columns of A
sum(e*A[,1])
round(sum(e*A[,2]), digits = 6)
```
This shows that the vector of residuals is orthogonal to the projection $p$ and the column space of $A$

### Problem Set 2
Modeling mpg from the UC Irvine Machine Learning dataset:
First I'll read in the data from the provided file.
```{r}
auto.mpg <- read.table('auto-mpg.data', 
                       col.names=c('displacement', 'horsepower', 'weight', 'acceleration', 'mpg'))
```
Now I'll convert the data frame into an $A$ and $b$ matrices:
```{r}
auto.A <- data.matrix(auto.mpg[,1:4])
auto.b <- data.matrix(auto.mpg[,5])
# Adding a column of ones for the Intercepts
intercept <- rep(1, nrow(auto.A))
auto.A <- cbind(intercept, auto.A)
head(auto.A)
head(auto.b)
```
Now that the data is represented by matrices it's possible to use Least Squares Regression to find an $\hat{x}$ that approximates the solution to $Ax = b$. The next step is to create the matrices $A^T A$ and $A^T b$:
```{r}
auto.ATA <- t(auto.A) %*% auto.A
auto.ATb <- t(auto.A) %*% auto.b
```
Next I'll calcualte avalue for $\hat{x}$ by finding $(A^T A)^{-1} (A^T b)$
```{r}
auto.xhat <- solve(auto.ATA) %*% auto.ATb
auto.xhat
```
The above value for $\hat{x}$ gives us the bestfitting solution for the auto-mpg data. 
Now to calculate the fitting error for this solution.
```{r}
auto.p <- auto.A %*% auto.xhat
auto.e <- auto.b - auto.p
auto.error <- sum(auto.e^2)
auto.error
```